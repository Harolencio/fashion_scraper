{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy # for tweet mining\n",
    "import pandas as pd # for data manipulation and analysis\n",
    "import numpy as np # for working with arrays and carrying out mathematical operations. Pandas is built on Numpy\n",
    "import csv # to read and write csv files\n",
    "import re # In-built regular expressions library\n",
    "import string # Inbuilt string library\n",
    "import glob # to retrieve files/pathnames matching a specified pattern. \n",
    "import random # generating random numbers\n",
    "import requests # to send HTTP requests\n",
    "\n",
    "\n",
    "# Set the limits for Pandas Dataframe display to avoid potential system freeze\n",
    "pd.set_option(\"display.max_rows\", 15)\n",
    "pd.set_option(\"display.max_columns\", 15)\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'yIOU1MzMbYaGt0XXq0oXRPEMk'\n",
    "consumer_secret = 'QYIXXAewEVKchqrHL4R9TFSFmMgqXnqCSU1hnEeuFXSlxk1Znw'\n",
    "access_key= '1539289168194551809-9M27Avv9BVp8dFW6yVnWLYnvEo5BSN'\n",
    "access_secret = 'Ogp1BVzWtuDtRIKvXCKDCpRTMWsxQSCf2yOsxsxCIGaDC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) # Pass in Consumer key and secret for authentication by API\n",
    "auth.set_access_token(access_key, access_secret) # Pass in Access key and secret for authentication by API\n",
    "api = tweepy.API(auth) # Sleeps when API limit is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets2(search_query2, num_tweets2):\n",
    "    # Collect tweets using the Cursor object\n",
    "    # Each item in the iterator has various attributes that you can access to get information about each tweet\n",
    "    tweet_list2 = [tweets for tweets in tweepy.Cursor(api.search_tweets,\n",
    "                                    q=search_query2,\n",
    "                                    lang=\"en\",\n",
    "                                    tweet_mode='extended').items(num_tweets2)]\n",
    "    # Begin scraping the tweets individually:\n",
    "    for tweet in tweet_list2[::-1]:\n",
    "        tweet_id = tweet.id # get Tweet ID result\n",
    "        created_at = tweet.created_at # get time tweet was created\n",
    "        text = tweet.full_text # retrieve full tweet text\n",
    "        location = tweet.user.location # retrieve user location\n",
    "        retweet = tweet.retweet_count # retrieve number of retweets\n",
    "        favorite = tweet.favorite_count # retrieve number of likes\n",
    "        with open('test.csv','a', newline='', encoding='utf-8') as csvFile2:\n",
    "            csv_writer2 = csv.writer(csvFile2, delimiter=',') # create an instance of csv object\n",
    "            csv_writer2.writerow([tweet_id, created_at, text, location, retweet, favorite]) # write each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 Forbidden\n453 - You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, you’ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m search_query2 \u001b[38;5;241m=\u001b[39m search_words2 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m -filter:links AND -filter:retweets AND -filter:replies\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#with open('test.csv', encoding='utf-8') as data:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#latest_tweet = int(list(csv.reader(data))[-1][0]) # Return the most recent tweet ID\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#get_tweets2(search_query2, 10, latest_tweet)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mget_tweets2\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_query2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [20], line 4\u001b[0m, in \u001b[0;36mget_tweets2\u001b[1;34m(search_query2, num_tweets2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_tweets2\u001b[39m(search_query2, num_tweets2):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Collect tweets using the Cursor object\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Each item in the iterator has various attributes that you can access to get information about each tweet\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     tweet_list2 \u001b[38;5;241m=\u001b[39m [tweets \u001b[38;5;28;01mfor\u001b[39;00m tweets \u001b[38;5;129;01min\u001b[39;00m tweepy\u001b[38;5;241m.\u001b[39mCursor(api\u001b[38;5;241m.\u001b[39msearch_tweets,\n\u001b[0;32m      5\u001b[0m                                     q\u001b[38;5;241m=\u001b[39msearch_query2,\n\u001b[0;32m      6\u001b[0m                                     lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m                                     tweet_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextended\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mitems(num_tweets2)]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Begin scraping the tweets individually:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tweet_list2[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n",
      "Cell \u001b[1;32mIn [20], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_tweets2\u001b[39m(search_query2, num_tweets2):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Collect tweets using the Cursor object\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Each item in the iterator has various attributes that you can access to get information about each tweet\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     tweet_list2 \u001b[38;5;241m=\u001b[39m [tweets \u001b[38;5;28;01mfor\u001b[39;00m tweets \u001b[38;5;129;01min\u001b[39;00m tweepy\u001b[38;5;241m.\u001b[39mCursor(api\u001b[38;5;241m.\u001b[39msearch_tweets,\n\u001b[0;32m      5\u001b[0m                                     q\u001b[38;5;241m=\u001b[39msearch_query2,\n\u001b[0;32m      6\u001b[0m                                     lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m                                     tweet_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextended\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mitems(num_tweets2)]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Begin scraping the tweets individually:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tweet_list2[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\harol\\ProjectDataScience\\data-science-environment\\venv\\lib\\site-packages\\tweepy\\cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext()\n",
      "File \u001b[1;32mc:\\Users\\harol\\ProjectDataScience\\data-science-environment\\venv\\lib\\site-packages\\tweepy\\cursor.py:286\u001b[0m, in \u001b[0;36mItemIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpage_index \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Reached end of current page, get the next page...\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpage_iterator)\n\u001b[0;32m    287\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    288\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_page \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpage_iterator)\n",
      "File \u001b[1;32mc:\\Users\\harol\\ProjectDataScience\\data-science-environment\\venv\\lib\\site-packages\\tweepy\\cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext()\n",
      "File \u001b[1;32mc:\\Users\\harol\\ProjectDataScience\\data-science-environment\\venv\\lib\\site-packages\\tweepy\\cursor.py:167\u001b[0m, in \u001b[0;36mIdIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 167\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod(max_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_id, parser\u001b[39m=\u001b[39mRawParser(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m    169\u001b[0m     model \u001b[39m=\u001b[39m ModelParser()\u001b[39m.\u001b[39mparse(\n\u001b[0;32m    170\u001b[0m         data, api \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[0;32m    171\u001b[0m         payload_list\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mpayload_list,\n\u001b[0;32m    172\u001b[0m         payload_type\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mpayload_type\n\u001b[0;32m    173\u001b[0m     )\n\u001b[0;32m    174\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mparser\u001b[39m.\u001b[39mparse(\n\u001b[0;32m    175\u001b[0m         data, api \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[0;32m    176\u001b[0m         payload_list\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mpayload_list,\n\u001b[0;32m    177\u001b[0m         payload_type\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod\u001b[39m.\u001b[39mpayload_type\n\u001b[0;32m    178\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\harol\\ProjectDataScience\\data-science-environment\\venv\\lib\\site-packages\\tweepy\\api.py:33\u001b[0m, in \u001b[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(method)\n\u001b[0;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 33\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\harol\\ProjectDataScience\\data-science-environment\\venv\\lib\\site-packages\\tweepy\\api.py:46\u001b[0m, in \u001b[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mpayload_list\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m payload_list\n\u001b[0;32m     45\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39mpayload_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m payload_type\n\u001b[1;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\harol\\ProjectDataScience\\data-science-environment\\venv\\lib\\site-packages\\tweepy\\api.py:1303\u001b[0m, in \u001b[0;36mAPI.search_tweets\u001b[1;34m(self, q, **kwargs)\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[39m@pagination\u001b[39m(mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1210\u001b[0m \u001b[39m@payload\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msearch_results\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearch_tweets\u001b[39m(\u001b[39mself\u001b[39m, q, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1212\u001b[0m     \u001b[39m\"\"\"search_tweets(q, *, geocode, lang, locale, result_type, count, \\\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \u001b[39m                     until, since_id, max_id, include_entities)\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[39m    .. _Twitter's documentation on the standard search API: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/overview\u001b[39;00m\n\u001b[0;32m   1302\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1303\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest(\n\u001b[0;32m   1304\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msearch/tweets\u001b[39m\u001b[39m'\u001b[39m, endpoint_parameters\u001b[39m=\u001b[39m(\n\u001b[0;32m   1305\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgeocode\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlang\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlocale\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mresult_type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1306\u001b[0m             \u001b[39m'\u001b[39m\u001b[39muntil\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msince_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmax_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minclude_entities\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1307\u001b[0m         ), q\u001b[39m=\u001b[39mq, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   1308\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\harol\\ProjectDataScience\\data-science-environment\\venv\\lib\\site-packages\\tweepy\\api.py:259\u001b[0m, in \u001b[0;36mAPI.request\u001b[1;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[39mraise\u001b[39;00m Unauthorized(resp)\n\u001b[0;32m    258\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m403\u001b[39m:\n\u001b[1;32m--> 259\u001b[0m     \u001b[39mraise\u001b[39;00m Forbidden(resp)\n\u001b[0;32m    260\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m404\u001b[39m:\n\u001b[0;32m    261\u001b[0m     \u001b[39mraise\u001b[39;00m NotFound(resp)\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 Forbidden\n453 - You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, you’ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve"
     ]
    }
   ],
   "source": [
    "search_words2 = \"\\\"2020 has been\\\"\" # Specifying exact phrase to search\n",
    "# Exclude Links, retweets, replies\n",
    "search_query2 = search_words2 + \" -filter:links AND -filter:retweets AND -filter:replies\" \n",
    "#with open('test.csv', encoding='utf-8') as data:\n",
    "    #latest_tweet = int(list(csv.reader(data))[-1][0]) # Return the most recent tweet ID\n",
    "#get_tweets2(search_query2, 10, latest_tweet)\n",
    "get_tweets2(search_query2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60f083665f9cb75505866baba5fefc6224937c012d45ddf8817359010af2da45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
